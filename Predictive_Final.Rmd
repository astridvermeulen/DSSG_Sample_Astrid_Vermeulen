---
title: "R Notebook"
output: html_notebook
---

***Importing Packages and Data***

```{r}
#rm(list = ls())

# Install packages
if (!require("pacman")) install.packages("pacman")
require("pacman", character.only = TRUE, quietly = TRUE)
p_load(tidyverse)
library("readxl")
p_load(lubridate)
library('stringr')
set.seed(123)
p_load(dummy)
p_load(varSelRF, Boruta)

# Load in Data
# first_cycling_data <- read.csv("Races_WITHindex.csv", header = TRUE)
# pro_cycling_data <- read_excel("RiderData.xlsx")
```

***Data Preparation***

```{r}
# #impute missing UCIs with 0 as missing values means that the driver finished outside of the points and thus did not earn any
# first_cycling_data$UCI[is.na(first_cycling_data$UCI)] <- 0
# 
# #merge on name and team (because what if a rider switches teams?)
# #merge Given Name and Family name to one column: Rider (necessary for merge)
# pro_cycling_data$Rider <- str_c(pro_cycling_data$`Family Name`, ' ', pro_cycling_data$`Given Name`)
# 
# # merge two data frames by ID
# basetable <- merge(first_cycling_data, pro_cycling_data,by="Rider")

# Load in Basetable
basetable <- get(load("basetable_merge_phase.Rdata"))

#transform position column to numbers
basetable$Pos <- as.integer(basetable$Pos)
basetable$Pos[is.na(basetable$Pos)] <- 100 #give the empty values a random number that does NOT indicate success (NA means DNF or DNS)

#check missing values
colSums(is.na(basetable))
#Var_9 has a high amount of missing values, as well as VAR_16, so we will drop those

#drop columns that are not of any use
drop <- c("X.x", "Rider_ID", "Team_ID", "ID", "Family Name", "Given Name", "Name", "Team.y", "Region", "ID2", "VAR10", "VAR9", "VAR16", "VAR25", "VAR26", "VAR23", "VAR24", "VAR29", "VAR27", "VAR28", "VAR21", "VAR22", "VAR20", "X.y", "VAR2", "VAR3", "VAR5", "VAR6", "VAR14", "VAR15", "Type", "VAR12", "VAR13", "VAR18", "Price", "VAR19", "VAR17", "VAR8", "VAR11", "VAR30", "VAR31", "Unnamed..1", "Icon")

# Drop variables above from basetable
basetable = basetable[,!(names(basetable) %in% drop)]

#get age of rider
basetable$Birthday <- ymd(basetable$Birthday)
basetable$age <- as.integer(floor(as.numeric(basetable$Year) - (as.numeric(format(basetable$Birthday, format = "%Y")))))
basetable$age[basetable$age > 100] <- NA
#drop birthday
drop <- c("Birthday")
basetable = basetable[,!(names(basetable) %in% drop)]

#As a tryout give riders points based on the F1 system
#If he rider comes first, he gets 10 points. If he is 2nd, 9 points
#All the way down to 1 point for place 10 till 60
#If you finish outside of top 60, 0 points
#Can be altered to be more forgiving
basetable$points <- ifelse(basetable$Pos == 1, 10, 
                           ifelse(basetable$Pos == 2, 9,
                                  ifelse(basetable$Pos == 3, 8,
                                         ifelse(basetable$Pos == 4, 7,
                                                ifelse(basetable$Pos == 5, 6,
                                                       ifelse(basetable$Pos == 6, 5,
                                                              ifelse(basetable$Pos == 7, 4,
                                                                     ifelse(basetable$Pos == 8, 3,
                                                                            ifelse(basetable$Pos == 9, 2,
                                                                                   ifelse(basetable$Pos >= 10 && basetable$Pos <= 60, 1, 0)
                                                                            )
                                                                     ))))))))

#Define that a driver has a specialty in a specific category if he has a score in that category above 75
#Exact cutoff also up for discussion, mcategories have a range between 50 and 85 (maybe have a look at the averages)
#https://web.cyanide-studio.com/games/cycling/2021/pcm/guide/basics-specialisations/
basetable$flat_driver <- ifelse(basetable$FLAT >= 75,1,0)
basetable$mountain_driver <- ifelse(basetable$MOUNTAIN >= 75,1,0)
basetable$downhill_driver <- ifelse(basetable$DOWNHILL >= 75,1,0)
basetable$cobbles_driver <- ifelse(basetable$COBBLES >= 75,1,0)
basetable$tt_driver <- ifelse(basetable$TT >= 75,1,0)
basetable$prologue_driver <- ifelse(basetable$PROLOGUE >= 75,1,0)
basetable$sprint_driver <- ifelse(basetable$SPRINT >= 75,1,0)
basetable$acceleration_driver <- ifelse(basetable$ACCELERATION >= 75,1,0)
basetable$resistance_driver <- ifelse(basetable$RESISTANCE >= 75,1,0)
basetable$endurance_driver <- ifelse(basetable$ENDURANCE >= 75,1,0)
basetable$recup_driver <- ifelse(basetable$RECUP >= 75,1,0)
basetable$hill_driver <- ifelse(basetable$HILL >= 75,1,0)
basetable$attack_driver <- ifelse(basetable$ATTACK >= 75,1,0)

#Everything gets grouped by Race_ID here, but a Race_ID can sometimes have multiple stages
#If a Race_ID is just a one day race, stage column is 0
#Make a new Race_ID_Stage , indicating the race id and stage in one column
basetable <- basetable %>%
  unite(Race_ID_Stage, Race_ID, Stage,
        remove = FALSE,
        sep = '_') %>%
  # Replace '_' with '' if it is at the end of the line
  mutate(Race_ID_Stage = gsub(', $', '', Race_ID_Stage))

#basetable_indep <- basetable[basetable$Year < 2020 & basetable$Year >= 2018,]
#basetable_dep <- basetable[basetable$Year == 2020,]

#Aggregate everything so that one row equals one team per race
#Variables inlcude team scores on different attributes, number of drivers with certain attributes
#Team points in the race and amount of top_X finishes per race
team_scores_per_race <-basetable_indep %>%
  group_by(Year, Race_ID_Stage, Team.x) %>%
  summarise(team_points = sum(points), team_popularity = sum(Popularity), team_potential = sum(Potential),
            team_score_flat = sum(FLAT), team_score_mountain = sum(MOUNTAIN), team_score_downhill = sum(DOWNHILL),
            team_score_cobbles = sum(COBBLES), team_score_tt = sum(TT), team_score_prologue = sum(PROLOGUE),
            team_score_sprint = sum(SPRINT), team_score_acceleration = sum(ACCELERATION), team_score_endurance = sum(ENDURANCE),
            team_score_resistance = sum(RESISTANCE), team_score_recup = sum(RECUP), team_score_hill = sum(HILL),
            team_score_attack = sum(ATTACK), 
            avg_team_size = mean(Size), avg_team_weight = mean(Weight),
            nr_drivers = n_distinct(Rider),
            nr_flat_drivers = sum(flat_driver), nr_mountain_drivers = sum(mountain_driver), nr_downhill_drivers = sum(downhill_driver),
            nr_cobbles_drivers = sum(cobbles_driver), nr_tt_drivers = sum(tt_driver), nr_prologue_drivers = sum(prologue_driver),
            nr_sprint_drivers = sum(sprint_driver), nr_acceleration_drivers = sum(acceleration_driver), nr_resistance_drivers =
              sum(resistance_driver), nr_endurance_drivers = sum(endurance_driver), nr_recup_drivers = sum(recup_driver), 
            nr_hill_drivers = sum(hill_driver), nr_attack_drivers = sum(attack_driver), avg_age_drivers = mean(age),
            #top20_finishes = sum(Pos <= 20), top10_finishes = sum(Pos <= 10), top5_finishes = sum(Pos <= 5), top3_finishes = sum(Pos <= 3)
            )

# Assign a category to each race, in line with the rider categories (done with help of stage_profiles in first cycling api and the stage profile icons on the site of firstcycling)
# In the html code you can see the name for the icon, that indicated the race category
# For the single day races we assign the category by hand
ids_single <- c("4_0", "7_0", "5_0", "8_0", "9_0", "11_0", "59_0", "58_0", "24_0", "47_0", "10_0", "1988_0", "20_0", "22_0", "1172_0", "53_0", "54_0", "75_0", "35_0", "40_0")
cats_single <- c("Flat", "Cobble", "Cobble", "Cobble", "Hill", "Hill", "Hill_UHF", "Hill", "Hill", "Cobble", "Hill_UHF", "Flat", "Flat", "Hill", "Hill", "Cobble", "Hill_UHF", "Cobble", "Hill", "Cobble")
race_cats_single <- data.frame(ids_single, cats_single)
race_cats_single <- race_cats_single %>%
  rename(Race_ID_Stage = ids_single, Race_Category = cats_single)

# For the races with multiple stages we extracted the profiles from the html response, with the help of python (see Cycling API.ipynb)
race_categories <- read.csv("race_categories.csv", header = TRUE)
unique(race_categories$Category)
#Translate the danish names we extracted from FC API
#UHF = up hill finish
race_categories <- race_categories %>% 
                        mutate(Race_Category = case_when(Category == "Flatt" ~ "Flat", Category == "Smaakupert-MF" ~ "Hill_UHF", Category == "Smaakupert"  ~ "Hill", Category == "Fjell" ~ "Mountain", Category == "Fjell-MF"   ~ "Mountain_UHF", Category == "Tempo" ~ "TimeTrial", Category == "Bakketempo"  ~ "TimeTrial", Category == "Brosten" ~ "Cobble",TRUE ~ "TimeTrial"))
#Make the same Race_ID_Stage as before
race_categories <- race_categories %>%
  unite(Race_ID_Stage, Race_ID, Stage,
        remove = FALSE,
        sep = '_') %>%
  # Replace ', ' with '' if it is at the end of the line
  mutate(Race_ID_Stage = gsub(', $', '', Race_ID_Stage))

drop <- c("Race_ID", "Stage", "Category")
race_categories = race_categories[,!(names(race_categories) %in% drop)]

#Join the categories to the team_scores df
team_scores_1 <- merge(team_scores_per_race, race_cats_single,by="Race_ID_Stage")
team_scores_2 <- merge(team_scores_per_race, race_categories,by= c("Year", "Race_ID_Stage"))
team_scores_per_race <- rbind(team_scores_1, team_scores_2)

hist(team_scores_per_race$team_points)
```

```{r}
## Dependent Period

# team_scores_per_race_dep <-basetable_dep %>%
#   group_by(Year, Race_ID_Stage, Team.x) %>%
#   summarise(team_points = sum(points), team_popularity = sum(Popularity), team_potential = sum(Potential),
#             team_score_flat = sum(FLAT), team_score_mountain = sum(MOUNTAIN), team_score_downhill = sum(DOWNHILL),
#             team_score_cobbles = sum(COBBLES), team_score_tt = sum(TT), team_score_prologue = sum(PROLOGUE),
#             team_score_sprint = sum(SPRINT), team_score_acceleration = sum(ACCELERATION), team_score_endurance = sum(ENDURANCE),
#             team_score_resistance = sum(RESISTANCE), team_score_recup = sum(RECUP), team_score_hill = sum(HILL),
#             team_score_attack = sum(ATTACK), 
#             avg_team_size = mean(Size), avg_team_weight = mean(Weight),
#             nr_drivers = n_distinct(Rider),
#             nr_flat_drivers = sum(flat_driver), nr_mountain_drivers = sum(mountain_driver), nr_downhill_drivers = sum(downhill_driver),
#             nr_cobbles_drivers = sum(cobbles_driver), nr_tt_drivers = sum(tt_driver), nr_prologue_drivers = sum(prologue_driver),
#             nr_sprint_drivers = sum(sprint_driver), nr_acceleration_drivers = sum(acceleration_driver), nr_resistance_drivers =
#               sum(resistance_driver), nr_endurance_drivers = sum(endurance_driver), nr_recup_drivers = sum(recup_driver), 
#             nr_hill_drivers = sum(hill_driver), nr_attack_drivers = sum(attack_driver), avg_age_drivers = mean(age),
#             top20_finishes = sum(Pos <= 20), top10_finishes = sum(Pos <= 10), top5_finishes = sum(Pos <= 5), top3_finishes = sum(Pos <= 3)
#             )
# 
# # Assign a category to each race, in line with the rider categories (done with help of stage_profiles in first cycling api and the stage profile icons on the site of firstcycling)
# # In the html code you can see the name for the icon, that indicated the race category
# # For the single day races we assign the category by hand
# ids_single <- c("4_0", "7_0", "5_0", "8_0", "9_0", "11_0", "59_0", "58_0", "24_0", "47_0", "10_0", "1988_0", "20_0", "22_0", "1172_0", "53_0", "54_0", "75_0", "35_0", "40_0")
# cats_single <- c("Flat", "Cobble", "Cobble", "Cobble", "Hill", "Hill", "Hill_UHF", "Hill", "Hill", "Cobble", "Hill_UHF", "Flat", "Flat", "Hill", "Hill", "Cobble", "Hill_UHF", "Cobble", "Hill", "Cobble")
# race_cats_single <- data.frame(ids_single, cats_single)
# race_cats_single <- race_cats_single %>%
#   rename(Race_ID_Stage = ids_single, Race_Category = cats_single)
# 
# # For the races with multiple stages we extracted the profiles from the html response, with the help of python (see Cycling API.ipynb)
# race_categories <- read.csv("race_categories.csv", header = TRUE)
# unique(race_categories$Category)
# #Translate the danish names we extracted from FC API
# #UHF = up hill finish
# race_categories <- race_categories %>% 
#                         mutate(Race_Category = case_when(Category == "Flatt" ~ "Flat", Category == "Smaakupert-MF" ~ "Hill_UHF", Category == "Smaakupert"  ~ "Hill", Category == "Fjell" ~ "Mountain", Category == "Fjell-MF"   ~ "Mountain_UHF", Category == "Tempo" ~ "TimeTrial", Category == "Bakketempo"  ~ "TimeTrial", Category == "Brosten" ~ "Cobble",TRUE ~ "TimeTrial"))
# #Make the same Race_ID_Stage as before
# race_categories <- race_categories %>%
#   unite(Race_ID_Stage, Race_ID, Stage,
#         remove = FALSE,
#         sep = '_') %>%
#   # Replace ', ' with '' if it is at the end of the line
#   mutate(Race_ID_Stage = gsub(', $', '', Race_ID_Stage))
# 
# drop <- c("Race_ID", "Stage", "Category")
# race_categories = race_categories[,!(names(race_categories) %in% drop)]
# 
# #Join the categories to the team_scores df
# team_scores_1_dep <- merge(team_scores_per_race_dep, race_cats_single,by="Race_ID_Stage")
# team_scores_2_dep <- merge(team_scores_per_race_dep, race_categories,by= c("Year", "Race_ID_Stage"))
# team_scores_per_race_dep <- rbind(team_scores_1_dep, team_scores_2_dep)
# 
# hist(team_scores_per_race_dep$team_points)
```

***Defining Success***

```{r}
#success is defined as when the team scores at least 10 points
team_scores_per_race$success <- ifelse(team_scores_per_race$team_points >= 10, 1, 0)
team_scores_per_race$success <- as.factor(team_scores_per_race$success)

#team_scores_per_race <- team_scores_per_race[, c("Team.x","Race_ID_Stage", "success")]

#drop columns that are not of any use
drop <- c("Team.x", "Year", "team_points", "Race_ID", "Race_ID_Stage", "Stage")
team_scores_per_race = team_scores_per_race[,!(names(team_scores_per_race) %in% drop)]

#Make dummies from Race_category
dummies <- dummy(team_scores_per_race["Race_Category"])
#Set TimeTrial as reference category
dummies <- dummies %>%
  dplyr::select(!Race_Category_TimeTrial)
dummies <- dummies %>%
  mutate(across(everything(), as.factor))
team_scores_per_race <- team_scores_per_race %>%
  dplyr::select(!Race_Category) %>%
  bind_cols(dummies)

team_scores_per_race$Race_Category_Cobble <- as.numeric(team_scores_per_race$Race_Category_Cobble)
team_scores_per_race$Race_Category_Flat <- as.numeric(team_scores_per_race$Race_Category_Flat)
team_scores_per_race$Race_Category_Hill <- as.numeric(team_scores_per_race$Race_Category_Hill)
team_scores_per_race$Race_Category_Hill_UHF <- as.numeric(team_scores_per_race$Race_Category_Hill_UHF)
team_scores_per_race$Race_Category_Mountain <- as.numeric(team_scores_per_race$Race_Category_Mountain)
team_scores_per_race$Race_Category_Mountain_UHF <- as.numeric(team_scores_per_race$Race_Category_Mountain_UHF)

# basetable_final <- merge(team_scores_per_race, team_scores_per_race_dep,by=c("Race_ID_Stage", "Team.x"))
# table(basetable_final$success)
# team_scores_per_race <- basetable_final
```

***Train/Val/Test Split***

```{r}
# Inspect class imbalance
table(team_scores_per_race$success)

# create indicators randomize order of indicators
allind <- sample(x = 1:nrow(team_scores_per_race), size = nrow(team_scores_per_race))

# split in two equal parts
trainind <- allind[1:round(length(allind) * 0.5)]
trainsmallind <- allind[1:round(length(allind) * 0.25)]
valind <- allind[(round(length(allind) * 0.25) + 1):round(length(allind) * 0.5)]
testind <- allind[(round(length(allind) * (0.5)) + 1):length(allind)]

# actual subsetting
trainsmall <- team_scores_per_race[trainsmallind, ]
val <- team_scores_per_race[valind, ]
train <- team_scores_per_race[trainind, ]
test <- team_scores_per_race[testind, ]
```

***Class Imbalance***

```{r}
# Inspect class imbalance
table(train$success)

##OVERSAMPLING##

# Get indices of each group
success <- which(train$success == "1")
fail <- which(train$success == "0")

# See how many instances we would want to have equal number
# as majority_class
n_desired <- length(fail)

resampled_success <- sample(x = success, size = n_desired,
                            replace = TRUE)

print(resampled_success)

# Combine into one large data set
train <- train[c(resampled_success, fail),]
table(train$success)

trainsplit <- split(train,sample(rep(1:2, 3329)))
trainsmall <- trainsplit$`1`
val <- trainsplit$`2`
ytrainsmall <- trainsmall$success
trainsmall <- trainsmall[,names(trainsmall) != 'success']
yval <- val$success
val <- val[,names(val) != 'success']
```

***Variable Selection***

The selection is done on the training set! Test set is left untouched.

```{r}
# varSelRF ?varSelRF vars.drop.frac = 0.20, the fraction of
# variables dropped in each iteration, the higher this
# number, the more aggressive the feature selection Can be
# compared to a learning rate parameter in neural nets
# ntree = the number of trees in the first forest (like in
# randomForest) ntreeIterat = the number of trees to use in
# the subsequent forests It has been shown that more
# iterations do not lead to a better performance
rf_vsrf <- varSelRF(train[, !names(train) %in% c("success")], train$success, vars.drop.frac = 0.2, ntree = 500, ntreeIterat = 100)

# Check the variables that were selected. A lot less compared to Boruta
(varsel_vsrf <- rf_vsrf$selected.vars)

# Boruta doTrace = 0 means no tracing, 1 means reporting decision about each attribute as soon as it is justified, 2 means the same as 1, plus reporting each importance source run, 3 means the same as 2, plus reporting of hits assigned to yet undecided attributes.
(rf_boruta <- Boruta(train[, !names(train) %in% c("success")], train$success, doTrace = 0))
# Plot importance of variables
plot(rf_boruta)
# We just select the confirmed variables
(varsel_boruta <- names(rf_boruta$finalDecision[rf_boruta$finalDecision =="Confirmed"]))
names(rf_boruta$finalDecision[rf_boruta$finalDecision =="Rejected"])
# Only keep variables in trainsmall, val, train and test set that are confirmed by Boruta
trainsmall <- trainsmall[, names(trainsmall) %in% c(varsel_boruta,"success", "Race_Category_Cobble","Race_Category_Flat","Race_Category_Hill","Race_Category_Hill_UHF","Race_Category_Mountain","Race_Category_Mountain_UHF")]
val <- val[, names(val) %in% c(varsel_boruta,"success", "Race_Category_Cobble","Race_Category_Flat","Race_Category_Hill","Race_Category_Hill_UHF","Race_Category_Mountain","Race_Category_Mountain_UHF")]
train <- train[, names(train) %in% c(varsel_boruta,"success", "Race_Category_Cobble","Race_Category_Flat","Race_Category_Hill","Race_Category_Hill_UHF","Race_Category_Mountain","Race_Category_Mountain_UHF")]
test <- test[, names(test) %in% c(varsel_boruta,"success", "Race_Category_Cobble","Race_Category_Flat","Race_Category_Hill","Race_Category_Hill_UHF","Race_Category_Mountain","Race_Category_Mountain_UHF")]
```

***Modeling*** 

```{r}
##HYBRID ENSEMBLE##
#Reliable package?
p_load(hybridEnsemble) #https://rdrr.io/cran/hybridEnsemble/man/hybridEnsemble.html

ytrain <- train$success
train <- train[,names(train) != 'success']
ytest <- test$success
test <- test[,names(test) != 'success']

#GA can also be used as a combination method. Right now it is ; single best, simple mean and authority based weighting
#SV has difficulties with running (or just takes a really long time)
#NB throws an error I am not able to fix (don't know where this error is thrown, can't find it in source code)
#Other available algorithms are KF= Kernel Factory, NN= Bagged Neural Network,
#RoF= Rotation Forest and KN= Bagged K- Nearest Neighbors
# hE <- hybridEnsemble(x = train, y= ytrain, algorithms = c("LR", "RF", "AB"
#                                                           #"SV")
#                                                           ),
#                      verbose = TRUE, filter=NULL,
#                      # SV.gamma = 2^-15,
#                      # SV.cost = 2^-5,
#                      # SV.degree=2,
#                      # SV.kernel='radial'
# )
#                      
# predictions <- predict(object = hE, newdata=test, verbose=TRUE)

# CVhE <- CVhybridEnsemble(x = train, y= ytrain, algorithms = c("LR", "RF"), verbose = TRUE, filter=NULL)
#predictions <- predict(object = CVhE, newdata=test, verbose=TRUE)
# summary(CVhE, stat='median')
# plot(x=CVhE, ROCcurve = TRUE)


##HETEROGENOUS ENSEMBLE##
#No optimalisation of parameters done yet
#Slides mention that ideally 10 classifiers should be used in the ensemble
#Perform the individual classifier predictions on a validation set, only the final predictions should be done with the test set!
p_load(randomForest, xgboost, glmnet, AUC, e1071, FNN, catboost, fastAdaboost, lightgbm, rotationForest)

# models_function <- function(train, test, ytrain, ytest) {

#Train all the models
#LR
# On sufficiently small lambda
logreg <- cv.glmnet(x = data.matrix(train), y = ytrain, family = 'binomial',alpha = 0)

# predlr <- predict(logreg, newx = data.matrix(test),
#                        type = "response", s = 0.0003)
# 
# auc_lr <- AUC::auc(AUC::roc(predlr,ytest))

#NB
NB <- naiveBayes(x= train, y= ytrain)

# predNB <- predict(NB, test, type = "raw", threshold = 0.001)[,2]                                                       
# auc_nb <- AUC::auc(roc(predNB, factor(ytest)))

#KNN
# scaling
# stdev <- sapply(train, sd)
# means <- sapply(train, mean)
# trainKNN <- data.frame(t((t(train) - means)/stdev))
# testKNN <- data.frame(t((t(test) - means)/stdev))
# 
# # retrieve the indicators of the k nearest neighbors of the
# # query data
# #STILL NEED TO OPTIMIZE k!
# indicatorsKNN <- as.integer(knnx.index(data = trainKNN, query = testKNN,
#                                        k = k))
# # retrieve the actual y from the training set
# predKNNoptimal <- as.integer(as.character(ytrain[indicatorsKNN]))
# # if k > 1 then we take the proportion of 1s
# predKNNoptimal <- rowMeans(data.frame(matrix(data = predKNNoptimal,
#                                              ncol = k, nrow = nrow(testKNN))))
# # Evaluate
# AUC::auc(roc(predKNNoptimal, factor(ytest)))


#RF
rFmodel <- randomForest(x = train, y = ytrain,
                        ntree = 500, importance = TRUE)
# predrF <- predict(rFmodel, test, type = "prob")[, 2]
# auc_rf <- AUC::auc(AUC::roc(predrF, ytest))

#CATBoost
# ?catboost
# train_pool <- catboost.load_pool(data = data.matrix(train), 
#                                  label = as.numeric(as.character(ytrain)))
# # test_pool <- catboost.load_pool(data = data.matrix(test)) 
# #label = as.numeric(as.character(ytest)))
# #Default parameters
# params = list(loss_function = 'Logloss',
#               iterations = 100, 
#               depth = 6, 
#               learning_rate = 0.03,
#               l2_leaf_reg = 3, #L2 regularization term for the leaf nodes (also in xgboost)
#               metric_period=10)
# 
# 
# catboost_model <- catboost.train(train_pool,  NULL,
#                                        params = params)
# 
# predcatboost <- catboost.predict(catboost_model, test_pool, prediction_type = 'Probability')
# auc_catboost <- AUC::auc(AUC::roc(predcatboost, ytest))

#ADABoost
#Put in formula notation
train_ada <- train
train_ada$y <- ytrain
# test_ada <- test
# test_ada$y <- test

ABmodel <- adaboost(y ~ ., train_ada, nIter = 50) #Default iterations
# predAB <- predict(ABmodel, test)$prob[, 2]
# auc_ab <- AUC::auc(AUC::roc(predAB, ytest))

#Light GBM
#Randomly chosen parameters
param_set <- list(num_leaves = 4,
                        learning_rate = 0.05, objective = "binary",
                        boosting = "gbdt", num_iterations = 20)

lgbm_model <- lightgbm(data = as.matrix(train), params = param_set,
                       label = as.numeric(as.character(ytrain)), verbose = -1)

# predlgbm <- predict(lgbm_model, as.matrix(test))
# auc_lgbm <- AUC::auc(AUC::roc(predlgbm, ytest))

#Rotation Forest
train_rof <- sapply(train, as.numeric)
RoF <- rotationForest(x = train_rof, y = ytrain, L = 100)

# predRoF <- predict(RoF, test)
# auc_rof <- AUC::auc(AUC::roc(predRoF, ytest))

#XGB
#Right now with defaults, but xgboost will perform better if hyperparamters are tuned!
trainbig_xgb <- train %>%
  mutate_if(is.factor, as.character) %>% mutate_if(is.character, as.numeric)
train_xgb <- trainsmall %>%
  mutate_if(is.factor, as.character) %>% mutate_if(is.character, as.numeric)
val_xgb <- val %>%
  mutate_if(is.factor, as.character) %>% mutate_if(is.character, as.numeric)

# test_xgb <- test %>%
#   mutate_if(is.factor, as.character) %>% mutate_if(is.character, as.numeric)
# preparing matrices
dtrainbig <- xgb.DMatrix(data = as.matrix(trainbig_xgb), label = as.numeric(as.character(ytrain)))
dtrain <- xgb.DMatrix(data = as.matrix(train_xgb), label = as.numeric(as.character(ytrainsmall)))
dval <- xgb.DMatrix(data = as.matrix(val_xgb), label = as.numeric(as.character(yval)))
#dtest <- xgb.DMatrix(data = as.matrix(test_xgb))

# Set the hyperparameters
eta <- c(0.01, 0.1, 0.2, 0.5)
nround <- c(2, 5, 10, 20, 50, 100, 200)
gamma <- c(0.5, 1, 1.5, 2)

# create data frame of all possible combinations
params <- expand.grid(eta, nround, gamma)
colnames(params) <- c("eta", "nround", "gamma")
head(params, 20)

aucs_xgb <- vector()
for (row in 1:nrow(params)) {
  par <- params[row, ]
  xgb <- xgb.train(data = dtrain, eta = par$eta, nrounds = par$nround,
                   gamma = par$gamma, objective = "binary:logistic", verbose = 0)
  pred <- predict(xgb, dval)  # automatically knows to only use predictor variables
  aucs_xgb[row] <- AUC::auc(AUC::roc(pred, yval))
}

plot(1:nrow(params), aucs_xgb, type = "l", col = "green")

(optimal_params <- params[which.max(aucs_xgb), ])

xgb <- xgb.train(data = dtrainbig, eta = optimal_params$eta,
                 nrounds = optimal_params$nround, gamma = optimal_params$gamma,
                 objective = "binary:logistic", verbose = 0)

#xgb <- xgb.train(data = dtrain,
#                 objective = "binary:logistic", verbose = 0, nrounds=500)
# predxgb <- predict(xgb, dtest)
# auc_xgb <- AUC::auc(AUC::roc(predxgb, ytest))


# Weight according to performance
# finalpredictions <- (auc_lr/(auc_lr + auc_nb + auc_rf + auc_catboost + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predlr +
#                     (auc_nb/(auc_lr + auc_nb + auc_rf + auc_catboost + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predNB +
#                     (auc_rf/(auc_lr + auc_nb + auc_rf + auc_catboost + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predrF +
#                     (auc_catboost/(auc_lr + auc_nb + auc_rf + auc_catboost + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predcatboost +
#                     (auc_ab/(auc_lr + auc_nb + auc_rf + auc_catboost + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predAB +
#                     (auc_lgbm/(auc_lr + auc_nb + auc_rf + auc_catboost + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predlgbm +
#                     (auc_rof/(auc_lr + auc_nb + auc_rf + auc_catboost + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predRoF +
#                     (auc_xgb/(auc_lr + auc_nb + auc_rf + auc_catboost + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predxgb
# final_AUC <- AUC::auc(AUC::roc(finalpredictions, ytest))


#Make a function for all the predictions
predict_function <- function(test, ytest) {
predlr <- predict(logreg, newx = data.matrix(test),
                  type = "response", s = 0.0003)
auc_lr <- AUC::auc(AUC::roc(predlr,ytest))

predNB <- predict(NB, test, type = "raw", threshold = 0.001)[,2]                                                       
auc_nb <- AUC::auc(roc(predNB, factor(ytest)))

predrF <- predict(rFmodel, test, type = "prob")[, 2]
auc_rf <- AUC::auc(AUC::roc(predrF, ytest))

# test_pool <- catboost.load_pool(data = data.matrix(test)) 
# predcatboost <- catboost.predict(catboost_model, test_pool, prediction_type = 'Probability')
# auc_catboost <- AUC::auc(AUC::roc(predcatboost, ytest))

test_ada <- test
test_ada$y <- test
predAB <- predict(ABmodel, test)$prob[, 2]
auc_ab <- AUC::auc(AUC::roc(predAB, ytest))

predlgbm <- predict(lgbm_model, as.matrix(test))
auc_lgbm <- AUC::auc(AUC::roc(predlgbm, ytest))

predRoF <- predict(RoF, test)
auc_rof <- AUC::auc(AUC::roc(predRoF, ytest))

test_xgb <- test %>%
  mutate_if(is.factor, as.character) %>% mutate_if(is.character, as.numeric)
dtest <- xgb.DMatrix(data = as.matrix(test_xgb))
predxgb <- predict(xgb, dtest)
auc_xgb <- AUC::auc(AUC::roc(predxgb, ytest))

# Weight according to performance
finalpredictions <- (auc_lr/(auc_lr + auc_nb + auc_rf + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predlr +
  (auc_nb/(auc_lr + auc_nb + auc_rf + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predNB +
  (auc_rf/(auc_lr + auc_nb + auc_rf + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predrF +
  #(auc_catboost/(auc_lr + auc_nb + auc_rf + auc_catboost + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predcatboost +
  (auc_ab/(auc_lr + auc_nb + auc_rf + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predAB +
  (auc_lgbm/(auc_lr + auc_nb + auc_rf + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predlgbm +
  (auc_rof/(auc_lr + auc_nb + auc_rf  + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predRoF +
  (auc_xgb/(auc_lr + auc_nb + auc_rf  + auc_ab + auc_lgbm + auc_rof + auc_xgb)) * predxgb

final_AUC <- AUC::auc(AUC::roc(finalpredictions, ytest))

.GlobalEnv$final_preds <- finalpredictions
.GlobalEnv$final_AUC <- final_AUC
}
```

```{r}
#Make the final predictions
#resulting predicitions are in final_preds with a corresponding final_AUC
predict_function(test, ytest)
final_AUC
```

```{r}

```

